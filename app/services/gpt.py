"""GPT-Vision integration using the OpenAI client."""

from __future__ import annotations

import atexit
import base64
import json
import logging
import os
from pathlib import Path
from typing import Any

import httpx
from openai import APITimeoutError, OpenAI, OpenAIError

from .storage import detect_image_type, get_public_url

logger = logging.getLogger("gpt")


_client: OpenAI | None = None
_http_client: httpx.Client | None = None
_TEMPERATURE_DISABLED = False
_TEMPERATURE_WARNING_EMITTED = False
_MODEL = (os.environ.get("OPENAI_VISION_MODEL") or "gpt-5").strip() or "gpt-5"
_ASSISTANT_MODEL = (os.environ.get("OPENAI_ASSISTANT_MODEL") or _MODEL).strip() or _MODEL
_MODEL_FALLBACK_RAW = os.environ.get("OPENAI_VISION_MODEL_FALLBACK", "").strip()
_MODEL_FALLBACK = _MODEL_FALLBACK_RAW or None
_OPENAI_HOST = "api.openai.com"


def _should_bypass_proxy(host: str) -> bool:
    raw = os.environ.get("NO_PROXY") or os.environ.get("no_proxy")
    if not raw:
        return False
    host = host.lower().strip().lstrip(".")
    if not host:
        return False
    for entry in raw.split(","):
        token = entry.strip().lower()
        if not token:
            continue
        if token == "*":
            return True
        token = token.lstrip(".")
        if host == token or host.endswith("." + token):
            return True
    return False


def _get_client() -> OpenAI:
    """Lazily build and cache the OpenAI client."""

    global _client, _http_client
    if _client is None:
        mounts: dict[str, httpx.HTTPTransport] = {}
        http_proxy = os.environ.get("HTTP_PROXY")
        https_proxy = os.environ.get("HTTPS_PROXY")
        bypass_proxy = _should_bypass_proxy(_OPENAI_HOST)
        if not bypass_proxy:
            if http_proxy:
                mounts["http://"] = httpx.HTTPTransport(proxy=http_proxy)
            if https_proxy:
                mounts["https://"] = httpx.HTTPTransport(proxy=https_proxy)

        _http_client = httpx.Client(mounts=mounts) if mounts else None
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY environment variable is not set")
        _client = OpenAI(api_key=api_key, http_client=_http_client)
    return _client


def _close_client() -> None:
    global _client, _http_client
    if _http_client is not None:
        _http_client.close()
    _http_client = None
    _client = None


atexit.register(_close_client)

_PROMPT_FALLBACK = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç ¬´–ö–∞—Ä–º–∞–Ω–Ω—ã–π –∞–≥—Ä–æ–Ω–æ–º¬ª. –ü–æ–ª—É—á–∞–µ—à—å —Ñ–æ—Ç–æ —Ä–∞—Å—Ç–µ–Ω–∏—è –∏ –ø–æ–¥—Å–∫–∞–∑–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—à—å **—á–∏—Å—Ç—ã–π JSON**:
{
  "crop": "–∞–Ω–≥–ª./–ª–∞—Ç. –∫—É–ª—å—Ç—É—Ä–∞",
  "crop_ru": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ-—Ä—É—Å—Å–∫–∏",
  "disease": "–ª–∞—Ç–∏–Ω—Å–∫–æ–µ –∏–ª–∏ –∞–Ω–≥–ª. –Ω–∞–∑–≤–∞–Ω–∏–µ –±–æ–ª–µ–∑–Ω–∏",
  "disease_name_ru": "–±–æ–ª–µ–∑–Ω—å –ø–æ-—Ä—É—Å—Å–∫–∏",
  "confidence": 0.0-1.0,
  "reasoning": ["–∫—Ä–∞—Ç–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"],
  "treatment_plan": {
    "product": "–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ",
    "substance": "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–µ–π—Å—Ç–≤—É—é—â–µ–µ –≤–µ—â–µ—Å—Ç–≤–æ/–≥—Ä—É–ø–ø–∞",
    "dosage_value": 2.5,
    "dosage_unit": "–º–ª/10–ª",
    "method": "—Å–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
    "phi_days": 7,
    "phi": "—Å—Ç—Ä–æ–∫–∞ —Å–æ —Å—Ä–æ–∫–æ–º –æ–∂–∏–¥–∞–Ω–∏—è",
    "safety_note": "–º–µ—Ä—ã –∑–∞—â–∏—Ç—ã",
    "safety": "–¥–æ–ø. –∑–∞–º–µ—Ç–∫–∞"
  },
  "next_steps": {"reminder":"‚Ä¶","green_window":"‚Ä¶","cta":"‚Ä¶"},
  "need_reshoot": false,
  "reshoot_tips": ["–µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < 0.6 ‚Äî 2-3 —Å–æ–≤–µ—Ç–∞"],
  "need_clarify_crop": false,
  "clarify_crop_variants": ["–¥–æ 3 –∫—É–ª—å—Ç—É—Ä"],
  "assistant_ru": "–ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ",
  "assistant_followups_ru": ["–¥–æ 3 –≤–æ–ø—Ä–æ—Å–æ–≤"]
}

–ü—Ä–∞–≤–∏–ª–∞:
1. –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π JSON, –±–µ–∑ Markdown –∏ backtick.
2. –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å < 0.6 –∏–ª–∏ —Ñ–æ—Ç–æ –ø–ª–æ—Ö–æ–µ ‚Äî —Å—Ç–∞–≤—å need_reshoot=true, –¥–∞–≤–∞–π —Å–æ–≤–µ—Ç—ã –∏ —á–µ—Å—Ç–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π.
3. –î–∞–∂–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–ª–∞–Ω (–º–∏–Ω–∏–º—É–º substance + method + phi_days).
4. –£—á–∏—Ç—ã–≤–∞–π crop_hint, –Ω–æ –ø—Ä–æ–≤–µ—Ä—è–π –ø–æ —Ñ–æ—Ç–æ.
5. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ ‚Äî product –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –ø—É—Å—Ç—ã–º.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ `assistant_ru`:
- –ü–∏—à–∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ–¥—Ä–æ–±–Ω–æ, –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ:
  ```
  –≠—Ç–æ —Ä–∞—Å—Ç–µ–Ω–∏–µ ‚Äî –∞–≥–ª–∞–æ–Ω–µ–º–∞ (Aglaonema), –Ω–∞–∑—ã–≤–∞—é—Ç ¬´–∫–∏—Ç–∞–π—Å–∫–∏–º –≤–µ—á–Ω–æ–∑–µ–ª—ë–Ω—ã–º¬ª.

  üîç –ß—Ç–æ –≤–∏–¥–Ω–æ –Ω–∞ —Ñ–æ—Ç–æ:
  - ‚Ä¶
  - ‚Ä¶

  ‚öôÔ∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:
  - —Å—É—Ö–æ–π –≤–æ–∑–¥—É—Ö ‚Äî ‚Ä¶
  - –∂—ë—Å—Ç–∫–∞—è –≤–æ–¥–∞ ‚Äî ‚Ä¶

  üõ†Ô∏è –ß—Ç–æ –¥–µ–ª–∞—Ç—å:
  - –æ–±—Ä–∞–±–æ—Ç–∞–π –∏–Ω—Å–µ–∫—Ç–∏—Ü–∏–¥–æ–º‚Ä¶
  - —Å–ª–µ–¥–∏ –∑–∞ –≤–ª–∞–∂–Ω–æ—Å—Ç—å—é‚Ä¶

  ü™¥ –£—Ö–æ–¥ –¥–∞–ª—å—à–µ:
  - –ø–æ–ª–∏–≤ 1‚Äì2 —Ä–∞–∑–∞ –≤ –Ω–µ–¥–µ–ª—é‚Ä¶
  - –ø—Ä–æ—Ç–∏—Ä–∞–π –ª–∏—Å—Ç—å—è‚Ä¶
  ```
- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫—É–ª—å—Ç—É—Ä—ã, –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, –ø—Ä–∏—á–∏–Ω –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —à–∞–≥–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –±–ª–æ–∫–æ–≤, –¥–æ–±–∞–≤–ª—è–π –æ–±–æ–¥—Ä—è—é—â–µ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ.

`assistant_followups_ru` ‚Äî 2‚Äì3 –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ï—Å–ª–∏ –≤—Ä–µ–¥–∏—Ç–µ–ª–µ–π –Ω–µ—Ç, —á–µ—Å—Ç–Ω–æ –Ω–∞–ø–∏—à–∏ –∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ —É—Ö–æ–¥–µ. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤–Ω–µ JSON.
""".strip()


def _load_system_prompt() -> str:
    root = Path(__file__).resolve().parents[2]
    path = root / "prompts" / "diagnosis_system.md"
    try:
        return path.read_text(encoding="utf-8").strip()
    except OSError:
        logger.warning("Failed to read diagnosis_system.md, using fallback prompt")
        return _PROMPT_FALLBACK


_PROMPT = _load_system_prompt()


def _load_timeout() -> int:
    raw = os.environ.get("OPENAI_TIMEOUT_SECONDS")
    if not raw:
        return 60
    raw = raw.strip()
    if not raw:
        return 60
    try:
        value = int(float(raw))
    except ValueError:
        logger.warning("Invalid OPENAI_TIMEOUT_SECONDS '%s'; using default 60", raw)
        return 60
    if value <= 0:
        logger.warning("OPENAI_TIMEOUT_SECONDS must be positive, got %s; using default 60", raw)
        return 60
    return value


_TIMEOUT_SECONDS = _load_timeout()


def _get_temperature_setting() -> float | None:
    """Return configured temperature unless disabled or invalid."""

    global _TEMPERATURE_WARNING_EMITTED
    if _TEMPERATURE_DISABLED:
        return None

    raw = os.environ.get("OPENAI_TEMPERATURE")
    if raw is None:
        return None

    raw = raw.strip()
    if not raw:
        return None

    try:
        return float(raw)
    except ValueError:
        if not _TEMPERATURE_WARNING_EMITTED:
            logger.warning("Invalid OPENAI_TEMPERATURE '%s'; ignoring", raw)
            _TEMPERATURE_WARNING_EMITTED = True
        return None


def _is_temperature_rejection(exc: OpenAIError) -> bool:
    """Detect API errors that indicate temperature is unsupported."""

    error_body = getattr(exc, "body", None)
    if isinstance(error_body, dict):
        details = error_body.get("error")
        if isinstance(details, dict):
            param = str(details.get("param") or "").lower()
            if param == "temperature":
                return True
            message = str(details.get("message") or "").lower()
            if "temperature" in message:
                return True
            code = str(details.get("code") or "").lower()
            if "temperature" in code:
                return True

    message_attr = getattr(exc, "message", "") or ""
    message = str(message_attr or exc).lower()
    return "temperature" in message and (
        "default" in message or "supported" in message or "unsupported" in message
    )


def _execute_completion(client: OpenAI, kwargs: dict[str, Any]) -> Any:
    """Send request to OpenAI and normalize timeout errors."""

    try:
        return client.chat.completions.create(**kwargs)
    except APITimeoutError as exc:
        raise TimeoutError("OpenAI request timed out") from exc


def _build_image_source(key: str, image_bytes: bytes | None) -> str:
    if image_bytes:
        img_type = detect_image_type(image_bytes) or "jpeg"
        data = base64.b64encode(image_bytes).decode("ascii")
        return f"data:image/{img_type};base64,{data}"
    return get_public_url(key)


def _request_completion(client: OpenAI, model: str, base_payload: dict[str, Any]):
    request_kwargs = dict(base_payload)
    request_kwargs["model"] = model

    temperature = _get_temperature_setting()
    include_temperature = temperature is not None
    if include_temperature:
        request_kwargs["temperature"] = temperature

    try:
        return _execute_completion(client, request_kwargs)
    except OpenAIError as exc:  # pragma: no cover - network/SDK errors
        if include_temperature and _is_temperature_rejection(exc):
            global _TEMPERATURE_DISABLED
            _TEMPERATURE_DISABLED = True
            logger.warning(
                "OpenAI model %s rejected custom temperature; retrying with default.",
                model,
                exc_info=True,
            )
            retry_kwargs = {k: v for k, v in request_kwargs.items() if k != "temperature"}
            try:
                return _execute_completion(client, retry_kwargs)
            except OpenAIError as retry_exc:  # pragma: no cover
                logger.exception("GPT request failed: %s", retry_exc)
                raise RuntimeError("OpenAI request failed") from retry_exc
        logger.exception("GPT request failed: %s", exc)
        raise RuntimeError("OpenAI request failed") from exc


def call_gpt_vision(
    key: str, image_bytes: bytes | None = None, *, crop_hint: str | None = None
) -> dict:
    """Send photo to GPT‚ÄëVision and parse the diagnosis.

    Parameters
    ----------
    key: str
        S3 object key returned by :func:`app.services.storage.upload_photo`.
    image_bytes: Optional bytes to inline as data URI.
    """

    image_url = _build_image_source(key, image_bytes)

    client = _get_client()
    hint = (crop_hint or "").strip()
    hint_suffix = ""
    if hint:
        hint_clean = hint[:64]
        hint_suffix = (
            " –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –∫—É–ª—å—Ç—É—Ä—É: "
            f"{hint_clean}. –£—á–∏—Ç—ã–≤–∞–π –ø–æ–¥—Å–∫–∞–∑–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å —Ñ–æ—Ç–æ."
        )
    base_payload: dict[str, Any] = {
        "messages": [
            {"role": "system", "content": _PROMPT},
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "–û–ø—Ä–µ–¥–µ–ª–∏ –∫—É–ª—å—Ç—É—Ä—É, –ø—Ä–æ–±–ª–µ–º—É –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å JSON –ø–æ —Å—Ö–µ–º–µ –≤—ã—à–µ. "
                            "–û—Ç–≤–µ—Ç—å –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –Ω–æ –æ—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ JSON."
                            + hint_suffix
                        ),
                    },
                    {"type": "image_url", "image_url": {"url": image_url}},
                ],
            },
        ],
        "timeout": _TIMEOUT_SECONDS,
        "response_format": {"type": "json_object"},
    }

    try:
        response = _request_completion(client, _MODEL, base_payload)
    except TimeoutError as primary_timeout:
        fallback = _MODEL_FALLBACK if _MODEL_FALLBACK and _MODEL_FALLBACK != _MODEL else None
        if fallback:
            logger.warning(
                "Primary model %s timed out; falling back to %s.",
                _MODEL,
                fallback,
            )
            response = _request_completion(client, fallback, base_payload)
        else:
            raise primary_timeout

    try:
        payload = response.choices[0].message.content
        if isinstance(payload, list):
            fragments: list[str] = []
            for part in payload:
                text = part.get("text") if isinstance(part, dict) else getattr(part, "text", None)
                if text is None and hasattr(part, "content"):
                    text = getattr(part, "content")
                fragments.append(str(text or ""))
            payload_str = "".join(fragments)
        else:
            payload_str = str(payload or "")
        cleaned = payload_str.strip()
        logger.info("GPT JSON payload: %s", cleaned)
        data = json.loads(cleaned or "{}")
        crop = str(data["crop"]).strip()
        disease = str(data["disease"]).strip()
        crop_ru = _clean(data.get("crop_ru"))
        disease_name_ru = _clean(data.get("disease_name_ru"))
        confidence = float(data["confidence"])
        reasoning = _as_list(data.get("reasoning"))

        plan = _sanitize_plan(data.get("treatment_plan"))

        next_raw: Any = data.get("next_steps") or {}
        next_steps: dict[str, str] | None = None
        if isinstance(next_raw, dict):
            next_candidate = {
                "reminder": _clean(next_raw.get("reminder")),
                "green_window": _clean(next_raw.get("green_window")),
                "cta": _clean(next_raw.get("cta")),
            }
            if any(next_candidate.values()):
                next_steps = next_candidate

        need_reshoot = bool(data.get("need_reshoot"))
        reshoot_tips = _as_list(data.get("reshoot_tips"))
        need_clarify_crop = bool(data.get("need_clarify_crop"))
        clarify_crop_variants = _as_list(data.get("clarify_crop_variants"))
        assistant_ru = _clean(data.get("assistant_ru"))
        assistant_followups = _as_list(data.get("assistant_followups_ru"))
    except (KeyError, TypeError, ValueError, json.JSONDecodeError, IndexError) as exc:
        raise ValueError("Malformed GPT response") from exc

    return {
        "crop": crop,
        "disease": disease,
        "crop_ru": crop_ru or None,
        "disease_name_ru": disease_name_ru or None,
        "confidence": confidence,
        "reasoning": reasoning or None,
        "treatment_plan": plan,
        "next_steps": next_steps,
        "need_reshoot": need_reshoot,
        "reshoot_tips": reshoot_tips or None,
        "need_clarify_crop": need_clarify_crop,
        "clarify_crop_variants": clarify_crop_variants or None,
        "assistant_ru": assistant_ru or None,
        "assistant_followups_ru": assistant_followups or None,
    }


def call_gpt_chat(
    messages: list[dict[str, Any]],
    *,
    model: str | None = None,
    response_format: dict[str, Any] | None = None,
    timeout: float | None = None,
) -> str:
    """Send a text-only chat completion and return the raw content string."""

    client = _get_client()
    base_payload: dict[str, Any] = {
        "messages": messages,
        "timeout": timeout or _TIMEOUT_SECONDS,
    }
    if response_format is not None:
        base_payload["response_format"] = response_format
    response = _request_completion(client, model or _ASSISTANT_MODEL, base_payload)
    payload = response.choices[0].message.content
    if isinstance(payload, list):
        fragments: list[str] = []
        for part in payload:
            text = part.get("text") if isinstance(part, dict) else getattr(part, "text", None)
            if text is None and hasattr(part, "content"):
                text = getattr(part, "content")
            fragments.append(str(text or ""))
        return "".join(fragments)
    return str(payload or "")


def _clean(value: Any) -> str:
    if value is None:
        return ""
    return str(value).strip()


def _as_list(value: Any) -> list[str]:
    if isinstance(value, list):
        result = []
        for item in value:
            text = _clean(item)
            if text:
                result.append(text)
        return result
    text = _clean(value)
    return [text] if text else []


def _to_float(value: Any) -> float | None:
    if value in (None, ""):
        return None
    try:
        return float(value)
    except (TypeError, ValueError):
        return None


def _to_int(value: Any) -> int | None:
    if value in (None, ""):
        return None
    try:
        return int(float(value))
    except (TypeError, ValueError):
        return None


def _sanitize_plan(plan_raw: Any) -> dict[str, Any] | None:
    if not isinstance(plan_raw, dict):
        return None
    candidate: dict[str, Any] = {
        "product": _clean(plan_raw.get("product")),
        "substance": _clean(plan_raw.get("substance")),
        "dosage": _clean(plan_raw.get("dosage")),
        "dosage_value": _to_float(plan_raw.get("dosage_value")),
        "dosage_unit": _clean(plan_raw.get("dosage_unit")),
        "method": _clean(plan_raw.get("method")),
        "phi": _clean(plan_raw.get("phi")),
        "phi_days": _to_int(plan_raw.get("phi_days")),
        "safety_note": _clean(plan_raw.get("safety_note") or plan_raw.get("safety")),
        "safety": _clean(plan_raw.get("safety")),
    }
    core_ok = bool(
        candidate["substance"] or candidate["method"] or candidate["phi_days"] is not None
    )
    return candidate if core_ok else None


__all__ = ["call_gpt_vision", "call_gpt_chat"]
