# Руководство по hardening и мониторингу

Версия 1.0 — 2025-07-27

Данный документ описывает практики защиты и отладки проекта «Карманный агроном». Он предназначен для SRE/DevOps команды, которая обслуживает бота в production. Ниже приведены инструкции по запуску нагрузочных тестов k6, метрики для наблюдения, процесс ротации секретов и управление тарифным лимитом. Также даны ссылки на основные дашборды и схемы алёртов. Объём документа превышает пятьсот слов, чтобы вы имели все необходимые детали в одном месте.

## 1. Запуск k6 и наблюдаемые метрики

Нагрузочное тестирование проводится с помощью пакета [k6](https://k6.io/). В репозитории уже есть скрипт `load/full_journey.js`, который моделирует полный пользовательский сценарий: отправку фотографии, получение истории и оплату тарифа. Сценарий можно запускать как локально, так и в CI. Пример запуска вручную:

```bash
# поднимаем окружение для тестов
$ docker-compose up -d
# дожидаемся готовности API
$ until curl -sSf http://localhost:8000/docs; do sleep 2; done
# выполняем нагрузочный тест
$ docker run --network host -v $(pwd)/load:/scripts grafana/k6 run /scripts/full_journey.js \
    --env BASE_URL=http://localhost:8000 \
    --env API_KEY=test-api-key \
    --env API_VER=v1
```

По окончании k6 печатает JSON‑сводку со следующими полями:

- `http_req_duration_p95` — 95‑й перцентиль всех запросов.
- `http_req_duration_p99` — 99‑й перцентиль всех запросов.
- `error_rate` — доля ошибок (HTTP 5xx/4xx) от общего числа запросов.
- `diagnose_p95` — отдельная метрика для метода `/v1/ai/diagnose`.

Рекомендованные пороговые значения для production:

- `error_rate` < **1 %**
- `http_req_duration_p95` < **2000 мс**
- `diagnose_p95` < **8000 мс**

В CI ограничение проверяется в workflow `.github/workflows/perf.yml`. При превышении порогов job завершается ошибкой. Результаты также можно выгружать в Prometheus через плагин `k6-operator`, но в минимальном варианте достаточно стандартного вывода и последующей проверки скриптом на `jq`/`bc`.

## 2. Процесс ротации секретов

Секреты хранятся в [HashiCorp Vault](https://www.vaultproject.io/) и монтируются в поды через CSI. Ротация выполняется еженедельно скриптом `rotate_secrets.ts`. Скрипт запланирован в cron‑джобе Kubernetes: `0 3 * * 0` (каждое воскресенье в 03:00 МСК). Он выполняет следующие шаги:

1. Запрашивает новые значения ключей `GPT_API_KEY`, `SBP_SIGN_SECRET`, `DB_PASSWORD` и `S3_SECRET_KEY` в Vault.
2. Обновляет Kubernetes Secrets командой `kubectl apply -f`. Для безопасной замены используется шаблон манифеста из папки `k8s/secrets`.
3. После обновления выполняется `kubectl rollout restart deploy/app` и `deploy/worker`, чтобы поды получили новые переменные окружения.

По политике безопасности GPT‑ключ вращается **раз в месяц**, HMAC‑секрет для вебхуков — раз в 90 дней, а учётные данные к базе и S3 — раз в неделю. В случае срочного отзыва ключа ротацию можно запустить вручную: `node scripts/rotate_secrets.ts`. Скрипт логирует все шаги и уведомляет в Slack канал `#ops-notify` через вебхук. Историю изменений можно увидеть в Vault Audit Log.

## 3. Управление тарифным лимитом

Параметр `FREE_MONTHLY_LIMIT` определяет, сколько бесплатных диагностик доступно пользователю в месяц. По умолчанию значение равно 5, как указано в файле `.env.template`. Изменить лимит можно через переменную окружения или ConfigMap. Чтобы полностью отключить ограничение и убрать paywall, установите `FREE_MONTHLY_LIMIT=0` и перезапустите приложение:

```bash
kubectl set env deploy/app FREE_MONTHLY_LIMIT=0
kubectl rollout restart deploy/app deploy/worker
```

Возврат лимита выполняется аналогично, указав необходимое значение. Изменение вступает в силу после рестарта подов. Проверить новый лимит можно запросом к эндпоинту `/v1/limits` или через дашборд «Diagnosis» в Grafana. Важно следить, чтобы paywall корректно показывался при достигнутом лимите, и чтобы события превышения логировались в Loki: `quota_reject_total`.

## 4. Дашборды и схемы алёртов

Все основные метрики собираются в Prometheus и отображаются в Grafana. Ссылки на дашборды:

- **Diagnosis** — <https://grafana.example.com/d/diag-health>. Показывает `diag_latency_seconds`, `error_rate`, `quota_reject_total` и загрузку воркера.
- **Payments** — <https://grafana.example.com/d/payments>. Отслеживает время ответа `/payments` и частоту ошибок оплаты.
- **System Load** — <https://grafana.example.com/d/system-load>. Общие метрики CPU, RAM и состояние очереди.

Для алёртов используется Prometheus Alertmanager. Конфигурация описана в `docs/alerting.md`. Основные правила:

- `error_rate` > 2 % за 5 минут.
- `p95` эндпойнта `/diagnose` > 3 секунд.
- `queue_size_pending` > 100 элементов.

При срабатывании алёрта уведомления отправляются одновременно в Slack и Telegram. Шаблон сообщения включает имя сервиса, метрику и текущий порог. Перед внедрением изменений рекомендуется отправить тестовый алерт:

```bash
amtool alert add test_error rate=3
```

## 5. Прочие меры hardening

- Все публичные эндпойнты работают только по HTTPS. Внутренние вызовы к базе и S3 используют mTLS.
- Логи формируются в формате JSON и хранятся в Loki 30 дней. Для поиска по пользователю используйте поле `user_id`.
- Таймаут ответа GPT ограничен до 20 секунд. Повторные попытки обрабатываются воркером `retry_worker` с параметром `RETRY_LIMIT=3`.
- Миграции базы выполняются через Alembic. В случае нештатной ситуации откатить изменения можно командой `alembic downgrade` до предыдущего тега.

Следуя этому руководству, вы сможете поддерживать сервис в стабильном и безопасном состоянии. Каждый раздел сопровождается практическими примерами команд и ссылками на существующие инструменты проекта. При добавлении новых фич или изменении инфраструктуры обновляйте данный документ, чтобы он всегда отражал актуальную конфигурацию и процессы.
